{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Summarization NLP Project - Final Notebook\n",
    "\n",
    "**Course:** Natural Language Processing  \n",
    "**Student:** [Your Name]  \n",
    "**Date:** [Current Date]  \n",
    "**Project:** Dialogue Summarization using Fine-tuned BART Model\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Project Overview](#project-overview)\n",
    "2. [Setup and Installation](#setup-and-installation)\n",
    "3. [Data Exploration](#data-exploration)\n",
    "4. [Model Training](#model-training)\n",
    "5. [Evaluation](#evaluation)\n",
    "6. [Web Application](#web-application)\n",
    "7. [Results and Analysis](#results-and-analysis)\n",
    "8. [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Project Overview <a name=\"project-overview\"></a>\n",
    "\n",
    "This project implements a text summarization system using a fine-tuned BART model. We use the DialogSum dataset for training and create a Flask web application for deployment.\n",
    "\n",
    "### Project Goals:\n",
    "1. Fine-tune BART model on dialogue summarization\n",
    "2. Create a web interface for text summarization\n",
    "3. Evaluate model performance using ROUGE metrics\n",
    "4. Deploy as a complete NLP application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import project modules\n",
    "from src.inference import TextSummarizer\n",
    "from src.utils import load_sample_data\n",
    "from data import load_dataset\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup and Installation <a name=\"setup-and-installation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Python version\n",
    "import platform\n",
    "print(f\"Python version: {platform.python_version()}\")\n",
    "\n",
    "# Check PyTorch and CUDA\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No GPU detected. Training will be slower.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Exploration <a name=\"data-exploration\"></a>\n",
    "\n",
    "Let's explore the DialogSum dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DialogSum dataset\n",
    "print(\"üì¶ Loading DialogSum dataset...\")\n",
    "\n",
    "try:\n",
    "    from datasets import load_dataset\n",
    "    \n",
    "    # Load dataset\n",
    "    dataset = load_dataset(\"knkarthick/dialogsum\")\n",
    "    \n",
    "    print(f\"‚úÖ Dataset loaded successfully!\")\n",
    "    print(f\"   Train: {len(dataset['train'])} samples\")\n",
    "    print(f\"   Validation: {len(dataset['validation'])} samples\")\n",
    "    print(f\"   Test: {len(dataset['test'])} samples\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading dataset: {e}\")\n",
    "    print(\"Install with: pip install datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample from dataset\n",
    "if 'dataset' in locals():\n",
    "    sample = dataset['train'][0]\n",
    "    \n",
    "    print(\"üìÑ Sample Dialogue:\")\n",
    "    print(\"=\"*50)\n",
    "    print(sample['dialogue'])\n",
    "    \n",
    "    print(\"\\nüìù Summary:\")\n",
    "    print(\"=\"*50)\n",
    "    print(sample['summary'])\n",
    "    \n",
    "    print(f\"\\nüè∑Ô∏è  Topic: {sample['topic']}\")\n",
    "    \n",
    "    # Calculate statistics\n",
    "    dialogue_words = len(sample['dialogue'].split())\n",
    "    summary_words = len(sample['summary'].split())\n",
    "    compression_ratio = dialogue_words / summary_words\n",
    "    \n",
    "    print(f\"\\nüìä Statistics:\")\n",
    "    print(f\"   Dialogue: {dialogue_words} words\")\n",
    "    print(f\"   Summary: {summary_words} words\")\n",
    "    print(f\"   Compression: {compression_ratio:.1f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Calculate lengths for first 1000 samples\n",
    "sample_size = 1000\n",
    "dialogue_lengths = []\n",
    "summary_lengths = []\n",
    "\n",
    "for i in range(min(sample_size, len(dataset['train']))):\n",
    "    dialogue = dataset['train'][i]['dialogue']\n",
    "    summary = dataset['train'][i]['summary']\n",
    "    \n",
    "    dialogue_lengths.append(len(dialogue.split()))\n",
    "    summary_lengths.append(len(summary.split()))\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Dialogue length distribution\n",
    "axes[0].hist(dialogue_lengths, bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0].set_xlabel('Number of Words')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Dialogue Length Distribution')\n",
    "axes[0].axvline(x=np.mean(dialogue_lengths), color='red', linestyle='--', \n",
    "               label=f'Mean: {np.mean(dialogue_lengths):.1f}')\n",
    "axes[0].legend()\n",
    "\n",
    "# Summary length distribution\n",
    "axes[1].hist(summary_lengths, bins=30, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "axes[1].set_xlabel('Number of Words')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Summary Length Distribution')\n",
    "axes[1].axvline(x=np.mean(summary_lengths), color='red', linestyle='--', \n",
    "               label=f'Mean: {np.mean(summary_lengths):.1f}')\n",
    "axes[1].legend()\n",
    "\n",
    "# Compression ratio\n",
    "compression_ratios = [d/s for d, s in zip(dialogue_lengths, summary_lengths) if s > 0]\n",
    "axes[2].hist(compression_ratios, bins=30, alpha=0.7, color='lightcoral', edgecolor='black')\n",
    "axes[2].set_xlabel('Compression Ratio (Dialogue/Summary)')\n",
    "axes[2].set_ylabel('Frequency')\n",
    "axes[2].set_title('Compression Ratio Distribution')\n",
    "axes[2].axvline(x=np.mean(compression_ratios), color='red', linestyle='--', \n",
    "               label=f'Mean: {np.mean(compression_ratios):.1f}x')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(\"üìä Dataset Statistics:\")\n",
    "print(f\"Average dialogue length: {np.mean(dialogue_lengths):.1f} words\")\n",
    "print(f\"Average summary length: {np.mean(summary_lengths):.1f} words\")\n",
    "print(f\"Average compression ratio: {np.mean(compression_ratios):.1f}x\")\n",
    "print(f\"\\nMinimum dialogue length: {np.min(dialogue_lengths)} words\")\n",
    "print(f\"Maximum dialogue length: {np.max(dialogue_lengths)} words\")\n",
    "print(f\"Minimum summary length: {np.min(summary_lengths)} words\")\n",
    "print(f\"Maximum summary length: {np.max(summary_lengths)} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training <a name=\"model-training\"></a>\n",
    "\n",
    "Let's train the BART model on the DialogSum dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training setup\n",
    "print(\"ü§ñ Setting up model training...\")\n",
    "\n",
    "import torch\n",
    "from transformers import (\n",
    "    BartForConditionalGeneration,\n",
    "    BartTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForSeq2Seq\n",
    ")\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load pretrained model and tokenizer\n",
    "model_name = \"facebook/bart-large-cnn\"\n",
    "print(f\"Loading model: {model_name}\")\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "model.to(device)\n",
    "\n",
    "print(f\"‚úÖ Model loaded: {model_name}\")\n",
    "print(f\"   Vocabulary size: {tokenizer.vocab_size}\")\n",
    "print(f\"   Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing function\n",
    "def preprocess_function(examples):\n",
    "    \"\"\"Preprocess dialogue and summary pairs for training.\"\"\"\n",
    "    # Tokenize inputs\n",
    "    inputs = examples[\"dialogue\"]\n",
    "    model_inputs = tokenizer(\n",
    "        inputs,\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    \n",
    "    # Tokenize targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            examples[\"summary\"],\n",
    "            max_length=150,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\"\n",
    "        )\n",
    "    \n",
    "    # Replace padding token id with -100 for loss calculation\n",
    "    labels[\"input_ids\"] = [\n",
    "        [(label if label != tokenizer.pad_token_id else -100) for label in label_seq]\n",
    "        for label_seq in labels[\"input_ids\"]\n",
    "    ]\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Apply preprocessing\n",
    "print(\"üîÑ Preprocessing dataset...\")\n",
    "\n",
    "# Use a subset for faster training (comment out for full training)\n",
    "train_subset = dataset[\"train\"].select(range(1000))  # Use 1000 samples for demo\n",
    "val_subset = dataset[\"validation\"].select(range(100))  # Use 100 samples for demo\n",
    "\n",
    "tokenized_train = train_subset.map(preprocess_function, batched=True)\n",
    "tokenized_val = val_subset.map(preprocess_function, batched=True)\n",
    "\n",
    "print(f\"‚úÖ Preprocessing complete\")\n",
    "print(f\"   Training samples: {len(tokenized_train)}\")\n",
    "print(f\"   Validation samples: {len(tokenized_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./models/bart-dialogsum\",\n",
    "    num_train_epochs=1,  # Use 1 epoch for demo (use 2 for real training)\n",
    "    per_device_train_batch_size=4,  # Reduced for demo\n",
    "    per_device_eval_batch_size=4,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=200,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    report_to=\"none\",\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "print(\"üöÄ Training configuration ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model (this might take some time)\n",
    "print(\"üéØ Starting model training...\")\n",
    "print(\"   This may take several minutes depending on your hardware.\")\n",
    "print(\"   For full training, set num_train_epochs=2 and use full dataset.\")\n",
    "\n",
    "train_result = trainer.train()\n",
    "\n",
    "print(\"‚úÖ Training completed!\")\n",
    "print(f\"   Final training loss: {train_result.training_loss:.4f}\")\n",
    "\n",
    "# Save the model\n",
    "trainer.save_model(\"./models/bart-dialogsum\")\n",
    "tokenizer.save_pretrained(\"./models/bart-dialogsum\")\n",
    "\n",
    "print(\"üíæ Model saved to ./models/bart-dialogsum/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation <a name=\"evaluation\"></a>\n",
    "\n",
    "Let's evaluate the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fine-tuned model\n",
    "print(\"üìÇ Loading fine-tuned model...\")\n",
    "\n",
    "try:\n",
    "    from transformers import pipeline\n",
    "    \n",
    "    # Check if GPU is available\n",
    "    device = 0 if torch.cuda.is_available() else -1\n",
    "    \n",
    "    # Load the summarization pipeline\n",
    "    summarizer = pipeline(\n",
    "        \"summarization\",\n",
    "        model=\"./models/bart-dialogsum\",\n",
    "        tokenizer=\"./models/bart-dialogsum\",\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Fine-tuned model loaded successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading model: {e}\")\n",
    "    print(\"Loading base model instead...\")\n",
    "    \n",
    "    # Fall back to base model\n",
    "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=device)\n",
    "    print(\"‚úÖ Base model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model with sample dialogues\n",
    "test_samples = [\n",
    "    \"#Person1#: Hi, how are you today?\\n#Person2#: I'm good, thank you! How about you?\\n#Person1#: I'm doing well, just busy with work.\",\n",
    "    \"#Person1#: Have you finished the report yet?\\n#Person2#: Not yet, I'm still working on the financial analysis section.\\n#Person1#: When do you think you'll be done? The meeting is tomorrow morning.\",\n",
    "    \"#Person1#: What are your plans for the weekend?\\n#Person2#: I'm thinking about going hiking. The weather should be nice.\\n#Person1#: That sounds fun. Which trail are you going to?\"\n",
    "]\n",
    "\n",
    "print(\"üß™ Testing model with sample dialogues...\\n\")\n",
    "\n",
    "for i, text in enumerate(test_samples):\n",
    "    print(f\"Test {i+1}:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Input ({len(text.split())} words):\\n{text}\\n\")\n",
    "    \n",
    "    # Generate summary\n",
    "    summary = summarizer(text, max_length=100, min_length=30, do_sample=False)\n",
    "    \n",
    "    print(f\"Generated Summary ({len(summary[0]['summary_text'].split())} words):\")\n",
    "    print(f\"{summary[0]['summary_text']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test dataset\n",
    "print(\"üìä Evaluating model on test dataset...\")\n",
    "\n",
    "# Use a small subset for evaluation\n",
    "test_subset = dataset[\"test\"].select(range(10))\n",
    "\n",
    "results = []\n",
    "for i in range(len(test_subset)):\n",
    "    sample = test_subset[i]\n",
    "    dialogue = sample[\"dialogue\"]\n",
    "    reference = sample[\"summary\"]\n",
    "    \n",
    "    # Generate summary\n",
    "    generated = summarizer(dialogue, max_length=150, min_length=40, do_sample=False)\n",
    "    generated_text = generated[0]['summary_text']\n",
    "    \n",
    "    # Calculate word counts\n",
    "    input_words = len(dialogue.split())\n",
    "    reference_words = len(reference.split())\n",
    "    generated_words = len(generated_text.split())\n",
    "    \n",
    "    results.append({\n",
    "        \"id\": i,\n",
    "        \"input_words\": input_words,\n",
    "        \"reference_words\": reference_words,\n",
    "        \"generated_words\": generated_words,\n",
    "        \"reference\": reference,\n",
    "        \"generated\": generated_text\n",
    "    })\n",
    "    \n",
    "print(f\"‚úÖ Evaluated {len(results)} samples\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nüìã Evaluation Results:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, result in enumerate(results[:3]):  # Show first 3 results\n",
    "    print(f\"\\nSample {i+1}:\")\n",
    "    print(f\"Input: {result['input_words']} words\")\n",
    "    print(f\"Reference: {result['reference_words']} words\")\n",
    "    print(f\"Generated: {result['generated_words']} words\")\n",
    "    print(f\"\\nReference Summary:\\n{result['reference']}\")\n",
    "    print(f\"\\nGenerated Summary:\\n{result['generated']}\")\n",
    "    print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Web Application <a name=\"web-application\"></a>\n",
    "\n",
    "Let's test the Flask web application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Flask app API\n",
    "print(\"üåê Testing Flask web application API...\")\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Sample text for testing\n",
    "test_text = \"#Person1#: Good morning, I'm here for my job interview.\\n#Person2#: Welcome! Please have a seat. Tell me about your previous experience.\\n#Person1#: I worked as a software developer for two years at TechCorp.\\n#Person2#: What programming languages are you familiar with?\"\n",
    "\n",
    "# Prepare request\n",
    "url = \"http://localhost:5000/api/summarize\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "data = {\n",
    "    \"text\": test_text,\n",
    "    \"max_length\": 120,\n",
    "    \"min_length\": 40\n",
    "}\n",
    "\n",
    "print(f\"\\nüì§ Sending request to: {url}\")\n",
    "print(f\"üìù Text length: {len(test_text.split())} words\")\n",
    "\n",
    "try:\n",
    "    # Note: The Flask app needs to be running for this to work\n",
    "    # Uncomment the following lines when the app is running\n",
    "    \n",
    "    # response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "    # result = response.json()\n",
    "    \n",
    "    # if result[\"success\"]:\n",
    "    #     print(\"‚úÖ API call successful!\")\n",
    "    #     print(f\"\\nüìã Summary:\\n{result['summary']}\")\n",
    "    #     print(f\"\\nüìä Statistics:\")\n",
    "    #     print(f\"   Input words: {result['statistics']['input_words']}\")\n",
    "    #     print(f\"   Summary words: {result['statistics']['summary_words']}\")\n",
    "    #     print(f\"   Compression: {result['statistics']['compression_ratio']}x\")\n",
    "    # else:\n",
    "    #     print(f\"‚ùå API error: {result.get('error', 'Unknown error')}\")\n",
    "    \n",
    "    print(\"\\n‚ö†Ô∏è  Note: Flask app is not running.\")\n",
    "    print(\"   To test the API, run: python app.py\")\n",
    "    print(\"   Then run this cell again.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of running the Flask app from notebook\n",
    "print(\"üöÄ Starting Flask web application...\")\n",
    "print(\"   This will start the web server. Press Ctrl+C to stop.\")\n",
    "\n",
    "# Note: This would normally start the Flask app\n",
    "# But in a notebook, we'll just show the code\n",
    "\n",
    "flask_code = \"\"\"\n",
    "# To run the Flask app:\n",
    "# 1. Open a terminal\n",
    "# 2. Navigate to project directory\n",
    "# 3. Run: python app.py\n",
    "# 4. Open browser to: http://localhost:5000\n",
    \"\"\"\n",
    "\n",
    "print(flask_code)\n",
    "\n",
    "print(\"\\nüåê Once running, you can access:\")\n",
    "print(\"   Web Interface: http://localhost:5000\")\n",
    "print(\"   API Endpoint: http://localhost:5000/api/summarize\")\n",
    "print(\"   Health Check: http://localhost:5000/api/health\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Results and Analysis <a name=\"results-and-analysis\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze results\n",
    "print(\"üìà Results Analysis\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate statistics from evaluation results\n",
    "if 'results' in locals() and results:\n",
    "    # Calculate compression ratios\n",
    "    compression_ratios = []\n",
    "    word_differences = []\n",
    "    \n",
    "    for result in results:\n",
    "        if result['generated_words'] > 0:\n",
    "            compression = result['input_words'] / result['generated_words']\n",
    "            compression_ratios.append(compression)\n",
    "            \n",
    "            # Difference from reference length\n",
    "            diff = abs(result['generated_words'] - result['reference_words'])\n",
    "            word_differences.append(diff)\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"Average compression ratio: {np.mean(compression_ratios):.1f}x\")\n",
    "    print(f\"Average length difference from reference: {np.mean(word_differences):.1f} words\")\n",
    "    print(f\"\\nSample compression ratios:\")\n",
    "    \n",
    "    # Create visualization
